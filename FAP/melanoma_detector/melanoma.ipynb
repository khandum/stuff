{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import ctypes\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import sys; sys.argv=['']; del sys\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Melanoma detection training')\n",
    "args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc1 = 0\n",
    "args.world_size = 1\n",
    "args.multiprocessing_distributed = False\n",
    "args.dist_url = 'http://localhost:3000'\n",
    "args.rank = 0\n",
    "args.gpu = None\n",
    "args.dist_backend = 'nccl'\n",
    "args.out_features = 3\n",
    "args.pretrained = True\n",
    "args.arch = 'resnext50_32x4d'\n",
    "args.workers = 4\n",
    "args.momentum = 0.9\n",
    "args.lr = 0.01\n",
    "args.weight_decay = 1e-4\n",
    "args.data = 'data'\n",
    "args.batch_size = 64\n",
    "args.start_epoch = 0\n",
    "args.epochs = 100\n",
    "args.save_model = 'resnext50-05092020-2.pth'\n",
    "args.evaluate = False\n",
    "args.print_freq = 2000\n",
    "args.print_freq_test = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if args.gpu is not None:\n",
    "            images = images.cuda(args.gpu, non_blocking=True)\n",
    "        target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 3))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if args.gpu is not None:\n",
    "                images = images.cuda(args.gpu, non_blocking=True)\n",
    "            target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 3))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args.print_freq_test == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename=args.save_model):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'best_{}'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args.lr * (0.1 ** (epoch // 20))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_worker(gpu, ngpus_per_node, args):\n",
    "    global best_acc1\n",
    "    args.gpu = gpu\n",
    "    if args.distributed:\n",
    "        if args.multiprocessing_distributed:\n",
    "            # For multiprocessing distributed training, rank needs to be the\n",
    "            # global rank among all the processes\n",
    "            args.rank = args.rank * ngpus_per_node + gpu\n",
    "        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n",
    "                                world_size=args.world_size, rank=args.rank)\n",
    "    if args.pretrained:\n",
    "        print(\"=> using pre-trained model '{}'\".format(args.arch))\n",
    "        model = models.__dict__[args.arch](pretrained=True)\n",
    "        \n",
    "    else:\n",
    "        print(\"=> creating model '{}'\".format(args.arch))\n",
    "        model = models.__dict__[args.arch]()\n",
    "    \n",
    "    model.fc.out_features = args.out_features\n",
    "    \n",
    "    if args.distributed:\n",
    "        # For multiprocessing distributed, DistributedDataParallel constructor\n",
    "        # should always set the single device scope, otherwise,\n",
    "        # DistributedDataParallel will use all available devices.\n",
    "        if args.gpu is not None:\n",
    "            torch.cuda.set_device(args.gpu)\n",
    "            model.cuda(args.gpu)\n",
    "            # When using a single GPU per process and per\n",
    "            # DistributedDataParallel, we need to divide the batch size\n",
    "            # ourselves based on the total number of GPUs we have\n",
    "            args.batch_size = int(args.batch_size / ngpus_per_node)\n",
    "            args.workers = int((args.workers + ngpus_per_node - 1) / ngpus_per_node)\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])\n",
    "        else:\n",
    "            model.cuda()\n",
    "            # DistributedDataParallel will divide and allocate batch_size to all\n",
    "            # available GPUs if device_ids are not set\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model)\n",
    "    elif args.gpu is not None:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        model = model.cuda(args.gpu)\n",
    "    else:\n",
    "        # DataParallel will divide and allocate batch_size to all available GPUs\n",
    "        if args.arch.startswith('alexnet') or args.arch.startswith('vgg'):\n",
    "            model.features = torch.nn.DataParallel(model.features)\n",
    "            model.cuda()\n",
    "        else:\n",
    "            model = torch.nn.DataParallel(model).cuda()\n",
    "    criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)\n",
    "    \n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "    traindir = os.path.join(args.data, 'train')\n",
    "    valdir = os.path.join(args.data, 'valid')\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        traindir,\n",
    "        transforms.Compose([\n",
    "            transforms.RandomRotation(30),\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "    \n",
    "    if args.distributed:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "    else:\n",
    "        train_sampler = None\n",
    "        \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        datasets.ImageFolder(valdir, transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=args.batch_size, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "    \n",
    "    if args.evaluate:\n",
    "        validate(val_loader, model, criterion, args)\n",
    "        return\n",
    "    \n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        if args.distributed:\n",
    "            train_sampler.set_epoch(epoch)\n",
    "        adjust_learning_rate(optimizer, epoch, args)\n",
    "\n",
    "        # train for one epoch\n",
    "        train(train_loader, model, criterion, optimizer, epoch, args)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        acc1 = validate(val_loader, model, criterion, args)\n",
    "\n",
    "        # remember best acc@1 and save checkpoint\n",
    "        is_best = acc1 > best_acc1\n",
    "        best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "        if not args.multiprocessing_distributed or (args.multiprocessing_distributed\n",
    "                and args.rank % ngpus_per_node == 0):\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'arch': args.arch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'best_acc1': best_acc1,\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "            }, is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():   \n",
    "    \n",
    "    ngpus_per_node = torch.cuda.device_count()\n",
    "    print(ngpus_per_node)\n",
    "    args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n",
    "    \n",
    "    if args.multiprocessing_distributed:\n",
    "        args.world_size = ngpus_per_node * args.world_size\n",
    "        mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, ))\n",
    "    else:\n",
    "        main_worker(args.gpu, ngpus_per_node, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "=> using pre-trained model 'resnext50_32x4d'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\administrator\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\cuda\\nccl.py:24: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][ 0/32]\tTime 37.364 (37.364)\tData 24.625 (24.625)\tLoss 8.6612e+00 (8.6612e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [0/3]\tTime 27.178 (27.178)\tLoss 7.4582e+00 (7.4582e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 51.333 Acc@5 100.000\n",
      "Epoch: [1][ 0/32]\tTime 24.829 (24.829)\tData 24.189 (24.189)\tLoss 6.7091e-01 (6.7091e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.226 (28.226)\tLoss 9.1005e-01 (9.1005e-01)\tAcc@1  57.81 ( 57.81)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 58.667 Acc@5 100.000\n",
      "Epoch: [2][ 0/32]\tTime 29.195 (29.195)\tData 28.544 (28.544)\tLoss 8.0626e-01 (8.0626e-01)\tAcc@1  65.62 ( 65.62)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.327 (27.327)\tLoss 8.4816e-01 (8.4816e-01)\tAcc@1  56.25 ( 56.25)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 66.667 Acc@5 100.000\n",
      "Epoch: [3][ 0/32]\tTime 26.773 (26.773)\tData 26.037 (26.037)\tLoss 6.5088e-01 (6.5088e-01)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.262 (27.262)\tLoss 9.2118e-01 (9.2118e-01)\tAcc@1  57.81 ( 57.81)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 60.000 Acc@5 100.000\n",
      "Epoch: [4][ 0/32]\tTime 32.916 (32.916)\tData 32.182 (32.182)\tLoss 7.3307e-01 (7.3307e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.690 (27.690)\tLoss 8.1797e-01 (8.1797e-01)\tAcc@1  59.38 ( 59.38)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 64.667 Acc@5 100.000\n",
      "Epoch: [5][ 0/32]\tTime 23.872 (23.872)\tData 23.144 (23.144)\tLoss 6.0043e-01 (6.0043e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.111 (27.111)\tLoss 8.6468e-01 (8.6468e-01)\tAcc@1  51.56 ( 51.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 66.667 Acc@5 100.000\n",
      "Epoch: [6][ 0/32]\tTime 29.601 (29.601)\tData 28.869 (28.869)\tLoss 6.5560e-01 (6.5560e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.160 (27.160)\tLoss 1.3528e+00 (1.3528e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 70.000 Acc@5 100.000\n",
      "Epoch: [7][ 0/32]\tTime 25.765 (25.765)\tData 25.100 (25.100)\tLoss 7.2713e-01 (7.2713e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.269 (27.269)\tLoss 1.0007e+00 (1.0007e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 73.333 Acc@5 100.000\n",
      "Epoch: [8][ 0/32]\tTime 25.969 (25.969)\tData 25.287 (25.287)\tLoss 6.1897e-01 (6.1897e-01)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.650 (28.650)\tLoss 7.8616e-01 (7.8616e-01)\tAcc@1  57.81 ( 57.81)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 74.667 Acc@5 100.000\n",
      "Epoch: [9][ 0/32]\tTime 25.392 (25.392)\tData 24.658 (24.658)\tLoss 4.7237e-01 (4.7237e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.220 (28.220)\tLoss 9.5651e-01 (9.5651e-01)\tAcc@1  56.25 ( 56.25)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 72.000 Acc@5 100.000\n",
      "Epoch: [10][ 0/32]\tTime 30.213 (30.213)\tData 29.477 (29.477)\tLoss 5.4102e-01 (5.4102e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.466 (27.466)\tLoss 7.8800e-01 (7.8800e-01)\tAcc@1  65.62 ( 65.62)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 74.000 Acc@5 100.000\n",
      "Epoch: [11][ 0/32]\tTime 29.048 (29.048)\tData 28.292 (28.292)\tLoss 8.2222e-01 (8.2222e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.203 (27.203)\tLoss 9.3990e-01 (9.3990e-01)\tAcc@1  60.94 ( 60.94)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 78.000 Acc@5 100.000\n",
      "Epoch: [12][ 0/32]\tTime 25.524 (25.524)\tData 24.859 (24.859)\tLoss 4.4742e-01 (4.4742e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.430 (27.430)\tLoss 9.1739e-01 (9.1739e-01)\tAcc@1  60.94 ( 60.94)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 69.333 Acc@5 100.000\n",
      "Epoch: [13][ 0/32]\tTime 25.813 (25.813)\tData 25.088 (25.088)\tLoss 6.0910e-01 (6.0910e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.259 (27.259)\tLoss 8.4018e-01 (8.4018e-01)\tAcc@1  65.62 ( 65.62)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 78.000 Acc@5 100.000\n",
      "Epoch: [14][ 0/32]\tTime 25.426 (25.426)\tData 24.701 (24.701)\tLoss 3.5944e-01 (3.5944e-01)\tAcc@1  85.94 ( 85.94)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.454 (27.454)\tLoss 7.6581e-01 (7.6581e-01)\tAcc@1  68.75 ( 68.75)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 73.333 Acc@5 100.000\n",
      "Epoch: [15][ 0/32]\tTime 30.250 (30.250)\tData 29.503 (29.503)\tLoss 4.3211e-01 (4.3211e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.348 (27.348)\tLoss 8.0038e-01 (8.0038e-01)\tAcc@1  65.62 ( 65.62)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 76.667 Acc@5 100.000\n",
      "Epoch: [16][ 0/32]\tTime 25.613 (25.613)\tData 24.898 (24.898)\tLoss 5.2038e-01 (5.2038e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.343 (27.343)\tLoss 8.7114e-01 (8.7114e-01)\tAcc@1  67.19 ( 67.19)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 74.000 Acc@5 100.000\n",
      "Epoch: [17][ 0/32]\tTime 30.701 (30.701)\tData 30.004 (30.004)\tLoss 3.3126e-01 (3.3126e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.414 (27.414)\tLoss 9.7538e-01 (9.7538e-01)\tAcc@1  64.06 ( 64.06)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 78.667 Acc@5 100.000\n",
      "Epoch: [18][ 0/32]\tTime 28.771 (28.771)\tData 28.045 (28.045)\tLoss 3.3266e-01 (3.3266e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.225 (27.225)\tLoss 1.0531e+00 (1.0531e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 71.333 Acc@5 100.000\n",
      "Epoch: [19][ 0/32]\tTime 24.829 (24.829)\tData 24.084 (24.084)\tLoss 3.7716e-01 (3.7716e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.270 (27.270)\tLoss 6.7101e-01 (6.7101e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 76.667 Acc@5 100.000\n",
      "Epoch: [20][ 0/32]\tTime 30.438 (30.438)\tData 29.712 (29.712)\tLoss 3.7320e-01 (3.7320e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.066 (27.066)\tLoss 7.9752e-01 (7.9752e-01)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 78.667 Acc@5 100.000\n",
      "Epoch: [21][ 0/32]\tTime 27.025 (27.025)\tData 26.296 (26.296)\tLoss 3.9204e-01 (3.9204e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.170 (27.170)\tLoss 7.1950e-01 (7.1950e-01)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 78.667 Acc@5 100.000\n",
      "Epoch: [22][ 0/32]\tTime 30.376 (30.376)\tData 29.713 (29.713)\tLoss 2.5254e-01 (2.5254e-01)\tAcc@1  85.94 ( 85.94)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.385 (28.385)\tLoss 8.6259e-01 (8.6259e-01)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.667 Acc@5 100.000\n",
      "Epoch: [23][ 0/32]\tTime 25.352 (25.352)\tData 24.696 (24.696)\tLoss 4.2244e-01 (4.2244e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.199 (27.199)\tLoss 8.2732e-01 (8.2732e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.667 Acc@5 100.000\n",
      "Epoch: [24][ 0/32]\tTime 31.695 (31.695)\tData 30.980 (30.980)\tLoss 1.9619e-01 (1.9619e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.002 (27.002)\tLoss 8.4434e-01 (8.4434e-01)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [25][ 0/32]\tTime 29.050 (29.050)\tData 28.309 (28.309)\tLoss 2.7739e-01 (2.7739e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 26.969 (26.969)\tLoss 7.4002e-01 (7.4002e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 79.333 Acc@5 100.000\n",
      "Epoch: [26][ 0/32]\tTime 30.584 (30.584)\tData 29.849 (29.849)\tLoss 2.2002e-01 (2.2002e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 26.930 (26.930)\tLoss 8.1520e-01 (8.1520e-01)\tAcc@1  68.75 ( 68.75)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 78.000 Acc@5 100.000\n",
      "Epoch: [27][ 0/32]\tTime 31.566 (31.566)\tData 30.827 (30.827)\tLoss 2.2603e-01 (2.2603e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 26.921 (26.921)\tLoss 9.2618e-01 (9.2618e-01)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.000 Acc@5 100.000\n",
      "Epoch: [28][ 0/32]\tTime 27.535 (27.535)\tData 26.816 (26.816)\tLoss 2.2542e-01 (2.2542e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 26.909 (26.909)\tLoss 8.0452e-01 (8.0452e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 76.667 Acc@5 100.000\n",
      "Epoch: [29][ 0/32]\tTime 26.425 (26.425)\tData 25.680 (25.680)\tLoss 3.6878e-01 (3.6878e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.457 (27.457)\tLoss 8.4364e-01 (8.4364e-01)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 79.333 Acc@5 100.000\n",
      "Epoch: [30][ 0/32]\tTime 25.635 (25.635)\tData 24.899 (24.899)\tLoss 1.5082e-01 (1.5082e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/3]\tTime 27.193 (27.193)\tLoss 7.5912e-01 (7.5912e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.667 Acc@5 100.000\n",
      "Epoch: [31][ 0/32]\tTime 27.468 (27.468)\tData 26.718 (26.718)\tLoss 2.8243e-01 (2.8243e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.268 (27.268)\tLoss 9.2454e-01 (9.2454e-01)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 78.667 Acc@5 100.000\n",
      "Epoch: [32][ 0/32]\tTime 28.516 (28.516)\tData 27.779 (27.779)\tLoss 2.5566e-01 (2.5566e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.723 (28.723)\tLoss 1.0397e+00 (1.0397e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 79.333 Acc@5 100.000\n",
      "Epoch: [33][ 0/32]\tTime 30.408 (30.408)\tData 29.706 (29.706)\tLoss 2.1252e-01 (2.1252e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.134 (27.134)\tLoss 6.6362e-01 (6.6362e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 78.667 Acc@5 100.000\n",
      "Epoch: [34][ 0/32]\tTime 25.890 (25.890)\tData 25.176 (25.176)\tLoss 2.8316e-01 (2.8316e-01)\tAcc@1  85.94 ( 85.94)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 26.998 (26.998)\tLoss 8.5010e-01 (8.5010e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 79.333 Acc@5 100.000\n",
      "Epoch: [35][ 0/32]\tTime 22.454 (22.454)\tData 21.716 (21.716)\tLoss 1.2675e-01 (1.2675e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 31.881 (31.881)\tLoss 7.8624e-01 (7.8624e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 77.333 Acc@5 100.000\n",
      "Epoch: [36][ 0/32]\tTime 30.725 (30.725)\tData 29.999 (29.999)\tLoss 1.9886e-01 (1.9886e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.003 (27.003)\tLoss 8.4372e-01 (8.4372e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.000 Acc@5 100.000\n",
      "Epoch: [37][ 0/32]\tTime 36.455 (36.455)\tData 35.739 (35.739)\tLoss 1.9695e-01 (1.9695e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.417 (27.417)\tLoss 9.1690e-01 (9.1690e-01)\tAcc@1  70.31 ( 70.31)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.667 Acc@5 100.000\n",
      "Epoch: [38][ 0/32]\tTime 29.770 (29.770)\tData 29.023 (29.023)\tLoss 2.3078e-01 (2.3078e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.431 (27.431)\tLoss 1.0330e+00 (1.0330e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 78.000 Acc@5 100.000\n",
      "Epoch: [39][ 0/32]\tTime 28.553 (28.553)\tData 27.796 (27.796)\tLoss 1.7650e-01 (1.7650e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.407 (28.407)\tLoss 7.3506e-01 (7.3506e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.667 Acc@5 100.000\n",
      "Epoch: [40][ 0/32]\tTime 27.869 (27.869)\tData 27.152 (27.152)\tLoss 2.5674e-01 (2.5674e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 26.951 (26.951)\tLoss 8.1036e-01 (8.1036e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 81.333 Acc@5 100.000\n",
      "Epoch: [41][ 0/32]\tTime 26.708 (26.708)\tData 25.980 (25.980)\tLoss 2.7459e-01 (2.7459e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.485 (27.485)\tLoss 7.8805e-01 (7.8805e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [42][ 0/32]\tTime 27.530 (27.530)\tData 26.809 (26.809)\tLoss 1.8321e-01 (1.8321e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.237 (27.237)\tLoss 7.5313e-01 (7.5313e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.000 Acc@5 100.000\n",
      "Epoch: [43][ 0/32]\tTime 24.655 (24.655)\tData 23.912 (23.912)\tLoss 1.6323e-01 (1.6323e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.166 (27.166)\tLoss 7.2019e-01 (7.2019e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.667 Acc@5 100.000\n",
      "Epoch: [44][ 0/32]\tTime 25.305 (25.305)\tData 24.648 (24.648)\tLoss 3.8208e-01 (3.8208e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 26.926 (26.926)\tLoss 7.5010e-01 (7.5010e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.667 Acc@5 100.000\n",
      "Epoch: [45][ 0/32]\tTime 24.229 (24.229)\tData 23.491 (23.491)\tLoss 2.3315e-01 (2.3315e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.233 (27.233)\tLoss 8.5392e-01 (8.5392e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.667 Acc@5 100.000\n",
      "Epoch: [46][ 0/32]\tTime 25.228 (25.228)\tData 24.508 (24.508)\tLoss 1.5752e-01 (1.5752e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.205 (27.205)\tLoss 8.9530e-01 (8.9530e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.667 Acc@5 100.000\n",
      "Epoch: [47][ 0/32]\tTime 27.600 (27.600)\tData 26.857 (26.857)\tLoss 2.0055e-01 (2.0055e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.320 (27.320)\tLoss 7.3923e-01 (7.3923e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.667 Acc@5 100.000\n",
      "Epoch: [48][ 0/32]\tTime 28.929 (28.929)\tData 28.192 (28.192)\tLoss 1.7444e-01 (1.7444e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.394 (27.394)\tLoss 8.5196e-01 (8.5196e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [49][ 0/32]\tTime 28.541 (28.541)\tData 27.804 (27.804)\tLoss 2.6491e-01 (2.6491e-01)\tAcc@1  85.94 ( 85.94)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.477 (27.477)\tLoss 8.0166e-01 (8.0166e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 78.667 Acc@5 100.000\n",
      "Epoch: [50][ 0/32]\tTime 26.892 (26.892)\tData 26.172 (26.172)\tLoss 1.2737e-01 (1.2737e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.401 (27.401)\tLoss 8.3014e-01 (8.3014e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [51][ 0/32]\tTime 28.854 (28.854)\tData 28.192 (28.192)\tLoss 1.1068e-01 (1.1068e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.394 (27.394)\tLoss 9.0273e-01 (9.0273e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 81.333 Acc@5 100.000\n",
      "Epoch: [52][ 0/32]\tTime 28.431 (28.431)\tData 27.724 (27.724)\tLoss 1.9571e-01 (1.9571e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 31.446 (31.446)\tLoss 8.9325e-01 (8.9325e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 81.333 Acc@5 100.000\n",
      "Epoch: [53][ 0/32]\tTime 27.215 (27.215)\tData 26.562 (26.562)\tLoss 3.4388e-01 (3.4388e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 28.571 (28.571)\tLoss 8.4494e-01 (8.4494e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.667 Acc@5 100.000\n",
      "Epoch: [54][ 0/32]\tTime 29.547 (29.547)\tData 28.819 (28.819)\tLoss 1.7921e-01 (1.7921e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 26.948 (26.948)\tLoss 9.5054e-01 (9.5054e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 81.333 Acc@5 100.000\n",
      "Epoch: [55][ 0/32]\tTime 31.840 (31.840)\tData 31.092 (31.092)\tLoss 1.3304e-01 (1.3304e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.190 (27.190)\tLoss 9.1385e-01 (9.1385e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.000 Acc@5 100.000\n",
      "Epoch: [56][ 0/32]\tTime 28.792 (28.792)\tData 28.003 (28.003)\tLoss 7.4313e-02 (7.4313e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.343 (27.343)\tLoss 8.4803e-01 (8.4803e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.667 Acc@5 100.000\n",
      "Epoch: [57][ 0/32]\tTime 34.384 (34.384)\tData 33.625 (33.625)\tLoss 2.5381e-01 (2.5381e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.234 (27.234)\tLoss 8.8142e-01 (8.8142e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [58][ 0/32]\tTime 30.587 (30.587)\tData 29.848 (29.848)\tLoss 2.5765e-01 (2.5765e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.151 (27.151)\tLoss 1.0166e+00 (1.0166e+00)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [59][ 0/32]\tTime 29.139 (29.139)\tData 28.388 (28.388)\tLoss 2.0762e-01 (2.0762e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.240 (27.240)\tLoss 8.4080e-01 (8.4080e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.667 Acc@5 100.000\n",
      "Epoch: [60][ 0/32]\tTime 24.332 (24.332)\tData 23.616 (23.616)\tLoss 1.8033e-01 (1.8033e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 29.034 (29.034)\tLoss 9.3928e-01 (9.3928e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Acc@1 83.333 Acc@5 100.000\n",
      "Epoch: [61][ 0/32]\tTime 22.766 (22.766)\tData 22.032 (22.032)\tLoss 1.0958e-01 (1.0958e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.099 (27.099)\tLoss 9.0191e-01 (9.0191e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 81.333 Acc@5 100.000\n",
      "Epoch: [62][ 0/32]\tTime 31.180 (31.180)\tData 30.456 (30.456)\tLoss 1.9555e-01 (1.9555e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.142 (27.142)\tLoss 8.6039e-01 (8.6039e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [63][ 0/32]\tTime 25.459 (25.459)\tData 24.703 (24.703)\tLoss 1.1860e-01 (1.1860e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.178 (27.178)\tLoss 8.6164e-01 (8.6164e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.667 Acc@5 100.000\n",
      "Epoch: [64][ 0/32]\tTime 26.481 (26.481)\tData 25.742 (25.742)\tLoss 1.2557e-01 (1.2557e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.243 (27.243)\tLoss 9.5322e-01 (9.5322e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.667 Acc@5 100.000\n",
      "Epoch: [65][ 0/32]\tTime 31.533 (31.533)\tData 30.782 (30.782)\tLoss 1.6993e-01 (1.6993e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.359 (27.359)\tLoss 8.8618e-01 (8.8618e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [66][ 0/32]\tTime 28.405 (28.405)\tData 27.666 (27.666)\tLoss 1.3466e-01 (1.3466e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.198 (27.198)\tLoss 9.1879e-01 (9.1879e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.667 Acc@5 100.000\n",
      "Epoch: [67][ 0/32]\tTime 28.034 (28.034)\tData 27.280 (27.280)\tLoss 1.7031e-01 (1.7031e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.143 (27.143)\tLoss 9.0440e-01 (9.0440e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [68][ 0/32]\tTime 26.146 (26.146)\tData 25.500 (25.500)\tLoss 1.2911e-01 (1.2911e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.223 (27.223)\tLoss 9.3486e-01 (9.3486e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.667 Acc@5 100.000\n",
      "Epoch: [69][ 0/32]\tTime 26.722 (26.722)\tData 25.981 (25.981)\tLoss 1.7186e-01 (1.7186e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.138 (27.138)\tLoss 8.6539e-01 (8.6539e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.000 Acc@5 100.000\n",
      "Epoch: [70][ 0/32]\tTime 33.073 (33.073)\tData 32.344 (32.344)\tLoss 1.0842e-01 (1.0842e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.159 (27.159)\tLoss 8.5111e-01 (8.5111e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [71][ 0/32]\tTime 26.132 (26.132)\tData 25.412 (25.412)\tLoss 1.7779e-01 (1.7779e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.366 (27.366)\tLoss 8.7087e-01 (8.7087e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [72][ 0/32]\tTime 33.225 (33.225)\tData 32.497 (32.497)\tLoss 2.9689e-01 (2.9689e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.335 (27.335)\tLoss 9.1132e-01 (9.1132e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 83.333 Acc@5 100.000\n",
      "Epoch: [73][ 0/32]\tTime 27.945 (27.945)\tData 27.217 (27.217)\tLoss 2.4845e-01 (2.4845e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.378 (27.378)\tLoss 8.4547e-01 (8.4547e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.667 Acc@5 100.000\n",
      "Epoch: [74][ 0/32]\tTime 28.004 (28.004)\tData 27.340 (27.340)\tLoss 2.9240e-01 (2.9240e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.455 (27.455)\tLoss 8.7766e-01 (8.7766e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [75][ 0/32]\tTime 24.305 (24.305)\tData 23.649 (23.649)\tLoss 3.6453e-01 (3.6453e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.287 (27.287)\tLoss 8.7785e-01 (8.7785e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 81.333 Acc@5 100.000\n",
      "Epoch: [76][ 0/32]\tTime 25.124 (25.124)\tData 24.385 (24.385)\tLoss 1.0411e-01 (1.0411e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.301 (27.301)\tLoss 9.2589e-01 (9.2589e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 83.333 Acc@5 100.000\n",
      "Epoch: [77][ 0/32]\tTime 32.092 (32.092)\tData 31.381 (31.381)\tLoss 2.5329e-01 (2.5329e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.416 (27.416)\tLoss 1.0032e+00 (1.0032e+00)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [78][ 0/32]\tTime 24.312 (24.312)\tData 23.587 (23.587)\tLoss 1.1004e-01 (1.1004e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.335 (27.335)\tLoss 8.5001e-01 (8.5001e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.667 Acc@5 100.000\n",
      "Epoch: [79][ 0/32]\tTime 33.182 (33.182)\tData 32.448 (32.448)\tLoss 2.0321e-01 (2.0321e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.247 (27.247)\tLoss 8.0344e-01 (8.0344e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [80][ 0/32]\tTime 30.646 (30.646)\tData 29.888 (29.888)\tLoss 2.6927e-01 (2.6927e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.368 (27.368)\tLoss 8.9607e-01 (8.9607e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 81.333 Acc@5 100.000\n",
      "Epoch: [81][ 0/32]\tTime 27.236 (27.236)\tData 26.499 (26.499)\tLoss 1.9092e-01 (1.9092e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.350 (27.350)\tLoss 8.6428e-01 (8.6428e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [82][ 0/32]\tTime 26.854 (26.854)\tData 26.168 (26.168)\tLoss 1.2463e-01 (1.2463e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.007 (27.007)\tLoss 9.1249e-01 (9.1249e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [83][ 0/32]\tTime 28.787 (28.787)\tData 28.068 (28.068)\tLoss 6.5222e-02 (6.5222e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 29.544 (29.544)\tLoss 9.2499e-01 (9.2499e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [84][ 0/32]\tTime 34.933 (34.933)\tData 34.205 (34.205)\tLoss 1.9224e-01 (1.9224e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.361 (27.361)\tLoss 9.1946e-01 (9.1946e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [85][ 0/32]\tTime 33.212 (33.212)\tData 32.482 (32.482)\tLoss 1.8017e-01 (1.8017e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.352 (27.352)\tLoss 8.7316e-01 (8.7316e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 81.333 Acc@5 100.000\n",
      "Epoch: [86][ 0/32]\tTime 29.027 (29.027)\tData 28.276 (28.276)\tLoss 2.1150e-01 (2.1150e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 32.446 (32.446)\tLoss 9.2873e-01 (9.2873e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 81.333 Acc@5 100.000\n",
      "Epoch: [87][ 0/32]\tTime 33.001 (33.001)\tData 32.263 (32.263)\tLoss 1.7557e-01 (1.7557e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.382 (27.382)\tLoss 8.8423e-01 (8.8423e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [88][ 0/32]\tTime 24.190 (24.190)\tData 23.453 (23.453)\tLoss 2.7123e-01 (2.7123e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.328 (27.328)\tLoss 8.1927e-01 (8.1927e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 80.000 Acc@5 100.000\n",
      "Epoch: [89][ 0/32]\tTime 28.774 (28.774)\tData 28.045 (28.045)\tLoss 1.4056e-01 (1.4056e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.595 (27.595)\tLoss 8.9995e-01 (8.9995e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 83.333 Acc@5 100.000\n",
      "Epoch: [90][ 0/32]\tTime 24.736 (24.736)\tData 24.022 (24.022)\tLoss 1.2449e-01 (1.2449e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.116 (27.116)\tLoss 8.2636e-01 (8.2636e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.667 Acc@5 100.000\n",
      "Epoch: [91][ 0/32]\tTime 23.099 (23.099)\tData 22.444 (22.444)\tLoss 2.1731e-01 (2.1731e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5 100.00 (100.00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/3]\tTime 27.095 (27.095)\tLoss 9.1393e-01 (9.1393e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [92][ 0/32]\tTime 27.619 (27.619)\tData 26.959 (26.959)\tLoss 9.0293e-02 (9.0293e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.207 (27.207)\tLoss 9.7677e-01 (9.7677e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.667 Acc@5 100.000\n",
      "Epoch: [93][ 0/32]\tTime 25.587 (25.587)\tData 24.850 (24.850)\tLoss 2.4343e-01 (2.4343e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.213 (27.213)\tLoss 9.2364e-01 (9.2364e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.667 Acc@5 100.000\n",
      "Epoch: [94][ 0/32]\tTime 23.088 (23.088)\tData 22.346 (22.346)\tLoss 1.6890e-01 (1.6890e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.132 (27.132)\tLoss 8.6293e-01 (8.6293e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.667 Acc@5 100.000\n",
      "Epoch: [95][ 0/32]\tTime 32.425 (32.425)\tData 31.675 (31.675)\tLoss 2.7697e-01 (2.7697e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.063 (27.063)\tLoss 9.3368e-01 (9.3368e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.667 Acc@5 100.000\n",
      "Epoch: [96][ 0/32]\tTime 32.643 (32.643)\tData 31.900 (31.900)\tLoss 2.0819e-01 (2.0819e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.220 (27.220)\tLoss 9.6706e-01 (9.6706e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.000 Acc@5 100.000\n",
      "Epoch: [97][ 0/32]\tTime 25.664 (25.664)\tData 25.010 (25.010)\tLoss 2.0242e-01 (2.0242e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 31.539 (31.539)\tLoss 8.7176e-01 (8.7176e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 81.333 Acc@5 100.000\n",
      "Epoch: [98][ 0/32]\tTime 27.245 (27.245)\tData 26.522 (26.522)\tLoss 2.0213e-01 (2.0213e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.141 (27.141)\tLoss 9.0497e-01 (9.0497e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 82.667 Acc@5 100.000\n",
      "Epoch: [99][ 0/32]\tTime 32.604 (32.604)\tData 31.866 (31.866)\tLoss 2.2775e-01 (2.2775e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5 100.00 (100.00)\n",
      "Test: [0/3]\tTime 27.118 (27.118)\tLoss 8.6359e-01 (8.6359e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5 100.00 (100.00)\n",
      " * Acc@1 83.333 Acc@5 100.000\n"
     ]
    }
   ],
   "source": [
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnext50_32x4d(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc.out_features = args.out_features\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "m_load = torch.load('best_resnext50-05092020-2.pth')\n",
    "model.load_state_dict(m_load[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "data_dir = args.data\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(), \n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "test_data = datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=test_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=args.batch_size, num_workers=args.workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.682682\n",
      "\n",
      "\n",
      "Test Accuracy: 79% (474/600)\n"
     ]
    }
   ],
   "source": [
    "test(test_loader, model, criterion, train_on_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from glob import glob \n",
    "\n",
    "img_path = np.array(glob(\"data/test/*/*\"))\n",
    "\n",
    "\n",
    "def predict(img_paths):\n",
    "    pred_rank1 = [] # Is melanoma?\n",
    "    pred_rank2 = [] # Is seborrheic?\n",
    "    transform = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])])\n",
    "    img1 = Image.open(img_paths)\n",
    "    img = transform(img1)\n",
    "    prediction = model(img[None,:].cuda())\n",
    "    prediction = F.softmax(prediction, dim=1)\n",
    "    pred_rank1.append(float(prediction.data[0][0]))\n",
    "    pred_rank2.append(float(prediction.data[0][2]))\n",
    "    return pred_rank1, pred_rank2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [07:21<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "model.eval()\n",
    "with open('results1.csv', 'w', newline='') as csvfile:\n",
    "    doc = csv.writer(csvfile)\n",
    "    doc.writerow(['Id', 'task_1', 'task_2'])\n",
    "    for i in tqdm(range(len(img_path))):\n",
    "        pred = predict(img_path[i])\n",
    "        #print(pred[0][0])\n",
    "        doc.writerow([img_path[i], pred[0][0], pred[1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 1 Score: 0.856\n",
      "Category 2 Score: 0.938\n",
      "Category 3 Score: 0.897\n"
     ]
    }
   ],
   "source": [
    "import get_results as results\n",
    "import pandas as pd\n",
    "\n",
    "y_true = pd.read_csv('ground_truth.csv')\n",
    "y_true = y_true[['task_1', 'task_2']].astype(float).to_numpy()\n",
    "\n",
    "#y_pred = pd.read_csv('sample_predictions.csv')\n",
    "y_pred = pd.read_csv('results1.csv')\n",
    "y_pred = y_pred[['task_1', 'task_2']].astype(float).to_numpy()\n",
    "\n",
    "results.plot_roc_auc(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
